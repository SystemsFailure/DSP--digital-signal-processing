Методы направленного поиска - это алгоритмы, которые позволяют найти оптимальное решение задачи, просматривая только ограниченное подмножество возможных вариантов.

Ниже приведены некоторые распространенные методы направленного поиска:
    1. Метод градиентного спуска - используется для поиска локального минимума или максимума функции. 
    Он основан на вычислении градиента функции и последующем шаге в направлении, противоположном градиенту.

    2. Метод наискорейшего спуска - аналогичен методу градиентного спуска, но вместо градиента используется производная функции. 
    Этот метод предполагает выбор шага таким образом, чтобы достичь наибольшего убывания функции.

    3. Алгоритм Бройдена-Флетчера-Гольдфарба-Шанно (BFGS) - это метод квазиньютоновского типа, который используется для численной оптимизации функций. 
    Он комбинирует шаги градиентного спуска и наискорейшего спуска для приближения к оптимальному решению.

    4. Рой пчел (англ. Particle Swarm Optimization, PSO) - это метаэвристический алгоритм, в котором популяция решений называется "роем". 
    Он моделирует поведение стаи пчел, чтобы искать оптимальные решения путем обмена информацией между решениями.

    5. Генетический алгоритм (ГА) - это эволюционный метод оптимизации, который моделирует процесс естественного отбора. 
    Он использует понятие генетического кода и операторы рекомбинации и мутации для эффективного поиска оптимального решения.

    6. Алгоритм имитации отжига (Simulated Annealing) - это алгоритм, основанный на металлургическом процессе охлаждения для уменьшения энергии системы. 
    Он ищет оптимальное решение, принимая и периодически отвергая худшие решения в зависимости от температуры.

Каждый из этих методов имеет свои преимущества и недостатки, и может быть применен для различных задач в зависимости от их характеристик.



Метод градиентного спуска - это оптимизационный алгоритм, используемый для поиска минимума или максимума функции. 
В основе алгоритма лежит использование производных функции для определения направления, в котором нужно двигаться, 
чтобы достичь экстремума.

Суть метода заключается в последовательном обновлении значений переменных с использованием градиента функции, 
который показывает направление наибольшего возрастания функции. Градиент вычисляется как вектор, 
состоящий из частных производных функции по каждой переменной.

Для использования метода градиентного спуска необходимо выполнить следующие шаги:
    1. Определить функцию, для которой необходимо найти минимум или максимум.
    2. Вычислить градиент функции, то есть частные производные по каждой переменной.
    3. Выбрать начальное значение переменных.
    4. Повторять следующие шаги, пока не достигнут требуемый уровень точности или не выполнено ограничение по количеству итераций:
    - Вычислить значение функции для текущих значений переменных.
    - Вычислить градиент функции для текущих значений переменных.
    - Обновить значения переменных, используя формулу градиентного спуска: новое значение = старое значение - learning rate * градиент.
    - Увеличить счетчик итераций.
    5. Вернуть финальные значения переменных, которые соответствуют найденному минимуму или максимуму функции.

Формула градиентного спуска выглядит следующим образом:
новое значение = старое значение - learning rate * градиент

Здесь learning rate - это параметр скорости обучения, определяющий размер шага, 
с которым изменяются переменные на каждой итерации. Оптимальный выбор learning rate является задачей самой оптимизации, 
и его следует подбирать экспериментально.

Метод градиентного спуска находит применение в машинном обучении и оптимизации моделей для нахождения наилучших значений параметров или весов. 
Он широко используется в алгоритмах глубокого обучения, таких как нейронные сети.



Формула градиентного спуска используется для обновления параметров модели в процессе обучения методом градиентного спуска. Формула имеет следующий вид:
    θ_new = θ_old - λ * ∇J(θ_old)
    где:
    - θ_new - новые значения параметров модели после обновления
    - θ_old - старые значения параметров модели перед обновлением
    - λ - скорость обучения (learning rate), коэффициент, который определяет величину шага при обновлении параметров. 
    Он должен быть выбран достаточно малым, чтобы избежать осцилляции или расходимости модели, но при этом достаточно большим, чтобы обучение происходило эффективно.
    - ∇J(θ_old) - градиент функции J(θ_old) по параметрам θ_old. Градиент показывает направление наибольшего изменения функции, 
    поэтому мы отнимаем от старых параметров модели градиент, чтобы двигаться в направлении уменьшения функции потерь.

Формула применяется последовательно для каждого батча обучающих данных или для каждого примера, 
в зависимости от выбранного подхода (batch gradient descent, stochastic gradient descent или mini-batch gradient descent). 
При обновлении параметров градиент рассчитывается с использованием метода обратного распространения ошибки (backpropagation) в нейронных сетях.

Xn+1 = Xn - λ * df(x) / dx, λ- шаг сходимости, n - 0,1,2,3...




Локальный минимум - это точка на графике функции, где она принимает наименьшее значение в окрестности этой точки. 
То есть, функция может иметь и другие, более низкие значения в других областях, 
но в данной точке она принимает наименьшее значение среди всех значений в некоторой окрестности.

Градиентный спуск может помочь найти такие локальные минимумы путем итерационного 
обновления текущего положения в противоположном направлении градиента функции. 
Он продолжает это обновление до тех пор, пока не будет достигнуто удовлетворительное условие остановки, 
такое как достижение маленькой ошибки или исчерпание определенного числа итераций.

Однако, градиентный спуск может сойтись к локальному минимуму, который не является глобальным минимумом. 
Локальный минимум - это минимум функции в ограниченной области пространства параметров, в то время как глобальный минимум - 
это абсолютный минимум функции во всем доступном пространстве параметров.

Чтобы избежать сходимости к локальным минимумам, могут использоваться различные подходы, 
такие как случайная инициализация начальных параметров, выполнение нескольких запусков градиентного спуска с 
разными начальными параметрами, использование более сложных алгоритмов оптимизации, таких как генетические 
алгоритмы или методы ветвей и границ.


////////// Метод градиентного спуска для двух параметров ////////// 

Метод градиентного спуска для двух параметров — это алгоритм оптимизации, 
используемый для минимизации функции от двух переменных. 
Градиентный спуск представляет собой итерационный процесс, 
в котором на каждом шаге выполняется шаг в направлении, противоположном градиенту функции.

Алгоритм градиентного спуска для двух параметров можно представить следующим образом:
    1. Инициализируем два параметра x и y случайными значениями.
    2. Вычисляем производную функции по параметрам x и y.
    3. Обновляем параметры x и y в направлении, противоположном градиенту функции, умноженном на шаговый размер (learning rate).
    x = x - learning_rate * d_fx
    y = y - learning_rate * d_fy
    4. Повторяем шаги 2-3 до сходимости или достижения максимального числа итераций.

Процесс итерации продолжается, пока не будет достигнута сходимость 
или заданное количество итераций. 
Сходимость может быть определена, например, 
по изменению значения функции или параметров меньше некоторого порогового значения.

Обратите внимание, что в алгоритме используется параметр learning rate, 
который определяет размер шага на каждой итерации градиентного спуска. 
Выбор правильного learning rate может оказать значительное влияние на эффективность алгоритма. 
Слишком большой learning rate может привести к расходимости, а слишком маленький может замедлить скорость сходимости.

Одним из основных недостатков градиентного спуска является то, что он может сходиться к локальному минимуму функции, а
 не к глобальному минимуму. Для преодоления этой проблемы были разработаны модификации метода, такие как стохастический 
 градиентный спуск или методы с моментом.
