Вот некоторые из наиболее часто используемых формул интегрирования:
1. Линейность интеграла:
∫(a*f(x) + b*g(x))dx = a*∫f(x)dx + b*∫g(x)dx
2. Интеграл от константы:
∫c dx = c*x + C, где C - постоянная
3. Интеграл от степенной функции:
∫x^n dx = (x^(n+1))/(n+1) + C, где n ≠ -1, C - постоянная
4. Интеграл от функции вида e^x:
∫e^x dx = e^x + C, где C - постоянная
5. Интеграл от функции вида ln(x):
∫(1/x) dx = ln|x| + C, где C - постоянная
6. Интеграл от тригонометрической функции:
∫sin(x) dx = -cos(x) + C, где C - постоянная
∫cos(x) dx = sin(x) + C, где C - постоянная
7. Интеграл от обратной функции:
∫(1/sqrt(1-x^2)) dx = arcsin(x) + C, где C - постоянная
∫(1/(1+x^2)) dx = arctan(x) + C, где C - постоянная
Это лишь некоторые базовые формулы интегрирования. Существует множество других формул и методов интегрирования, таких как интегрирование по частям и замена переменной.

Напомним: Интеграл - это математическое понятие, которое представляет собой обратную операцию дифференцирования и 
          используется для нахождения площади под кривой или общего накопленного изменения функции. Он обозначается символом "∫" и 
          выражается в виде определенного или неопределенного интеграла. 
          Интегралы имеют множество применений в различных областях науки и инженерии. Они используются для определения площади фигур, 
          вычисления объемов тел, определения центра тяжести, моделирования физических процессов, решения дифференциальных уравнений и многого другого. 
          Основные виды интегралов включают неопределенный интеграл, который находит первообразную функции, и определенный интеграл, 
          который вычисляет площадь под кривой на определенном интервале. 
          Интегралы являются важной частью математического анализа и находят применение во многих областях науки, техники и экономики, 
          где необходимо решать задачи, связанные с накоплением или вычислением некоторых величин.


Напомним: Двойной интеграл - это математический инструмент, используемый для вычисления площади или общего объема под поверхностью в двухмерном пространстве. 
          Он представляет собой интеграл функции двух переменных по площади или области на плоскости.
          Двойной интеграл может быть использован для решения различных задач, таких как вычисление площади фигур на плоскости или объема тела в трехмерном пространстве. 
          Он также может быть использован для нахождения средних значений функций двух переменных или для вычисления центра масс системы с заданной плотностью.
          Для вычисления двойного интеграла необходимо определить пределы интегрирования, что представляет собой область на плоскости, и подынтегральную функцию, 
          которая зависит от двух переменных. После решения интеграла получается числовое значение, которое отражает требуемую величину (площадь, объем и т.д.).
          Таким образом, двойной интеграл - это инструмент для вычисления площадей, объемов и других характеристик фигур и объектов в двухмерном пространстве.


1. Дифференцирование по константе:
   d/dx (C) = 0, где C - константа.
2. Дифференцирование степенной функции:
   d/dx (x^n) = n*x^(n-1), где n - любое вещественное число.
3. Дифференцирование функции суммы и разности:
   d/dx (f(x) + g(x)) = f'(x) + g'(x), 
   d/dx (f(x) - g(x)) = f'(x) - g'(x), где f(x) и g(x) - функции.
4. Дифференцирование произведения функций:
   d/dx (f(x) * g(x)) = f'(x) * g(x) + f(x) * g'(x), где f(x) и g(x) - функции.
5. Дифференцирование частного функций:
   d/dx (f(x) / g(x)) = (f'(x) * g(x) - f(x) * g'(x)) / (g(x))^2, где f(x) и g(x) - функции, g(x) ≠ 0.
6. Дифференцирование экспоненциальной функции:
   d/dx (e^x) = e^x.
7. Дифференцирование логарифмической функции:
   d/dx (ln(x)) = 1/x, где x > 0.
8. Дифференцирование тригонометрической функции:
   d/dx (sin(x)) = cos(x),
   d/dx (cos(x)) = -sin(x),
   d/dx (tan(x)) = sec^2(x),
   d/dx (sec(x)) = sec(x) * tan(x),
   d/dx (cosec(x)) = -cosec(x) * cot(x),
   d/dx (cot(x)) = -cosec^2(x).
9. Дифференцирование обратной функции:
   d/dx (f^(-1)(x)) = 1 / f'(f^(-1)(x)), где f^(-1) - обратная функция, f'(x) ≠ 0.
Это основные формулы дифференцирования, существуют и другие, специфичные для определенных функций.

Дифференцирование - это математическая операция, которая позволяет находить производные функций. 
В процессе дифференцирования находится скорость изменения функции в каждой точке, то есть её производная.


1) Для функции y = k, где k - константа, производная равна нулю: dy/dx = 0.
2) Для функции y = x^n, где n - любое число (кроме нуля), производная равна произведению показателя степени на коэффициент при x: dy/dx = n*x^(n-1).
3) Для функции y = sin(x), производная равна косинусу x: dy/dx = cos(x).
4) Для функции y = cos(x), производная равна минус синусу x: dy/dx = -sin(x).
5) Для функции y = e^x, где e - основание натурального логарифма, производная равна самой функции: dy/dx = e^x.
6) Для функции y = ln(x), где ln - натуральный логарифм, производная равна обратному значению x: dy/dx = 1/x.
7) Для функции y = a^x, где a - положительное число, производная равна произведению самой функции на натуральный логарифм основания: dy/dx = a^x * ln(a).
8) Для функций y = u(x) + v(x), где u(x) и v(x) - произвольные функции, производная равна сумме производных этих функций: dy/dx = du/dx + dv/dx.
9) Для функции y = c * u(x), где c - константа, а u(x) - произвольная функция, производная равна произведению константы на производную функции: dy/dx = c * du/dx.
10) Для функции y = u(x) * v(x), где u(x) и v(x) - произвольные функции, производная равна произведению первой функции на производную второй функции, 
    плюс произведение второй функции на производную первой функции: dy/dx = u(x)*dv/dx + v(x)*du/dx.
11) Для функции y = u(x) / v(x), где u(x) и v(x) - произвольные функции, производная равна (производная первой функции умножить на вторую функцию минус производная второй 
    функции умножить на первую функцию) делить на квадрат второй функции: dy/dx = (u(x)*dv/dx - v(x)*du/dx) / v(x)^2.
12) Для функции y = u(v(x)), где u - произвольная функция, а v - функция от x, производная равна произведению производной u от v на производную v от x: dy/dx = du/dv * dv/dx.


События бывают достоверными, невозможными и случайными.

Достоверным называют событие, которое в результате испытания (осуществления определенных действий, 
определённого комплекса условий) обязательно произойдёт. 
Например, в условиях земного тяготения подброшенная монета непременно упадёт вниз.

Невозможным называют событие, которое заведомо не произойдёт в результате испытания. 
Пример невозможного события: в условиях земного тяготения подброшенная монета улетит вверх.

И, наконец, событие называется случайным, если в результате испытания оно может, как произойти, так и не произойти,
при этом должен иметь место принципиальный критерий случайности: случайное событие – есть следствие случайных факторов, 
воздействие которых предугадать невозможно или крайне затруднительно. Пример: в результате броска монеты выпадет «орёл».  
В рассмотренном случае случайные факторы – это форма и физические характеристики монеты, сила/направление броска, сопротивление воздуха и т.д.


Любой результат испытания называется исходом, который, собственно и представляет собой появление определённого события. 
В частности, при подбрасывании монеты возможно 2 исхода (случайных события): выпадет орёл, выпадет решка. Естественно, подразумевается, 
что данное испытание проводится в таких условиях, что монета не может встать на ребро или, скажем, зависнуть в невесомости.


формула P=m/n - n - это размер полной группы несовместных равновероятных событий, m - число элементарных событий(из полной группы) благоприятных некоторому исходу 
                (для которого и вычисляется вероятность)

                Условия работы формулы - 1 События должны состовлять полную группу событий
                                         2 Каждое событие при проведении эксперемента должно возникать с равной вероятностью
                                         3 Никаких два события из группы не могут произойти одновременно

Противоположные события, формула : A- = 1 - P(A) - P(A) - сама вероятность возникнования события, A- - Противоположное событие


УСЛОВНАЯ ВЕРОЯТНОСТЬ. ЗАВИСИМЫЕ И НЕЗАВИСИМЫЕ СОБЫТИЯ. ПРОИЗВЕДЕНИЕ СОБЫТИЙ (Условное И)

Зависимые события - это события, которые влияют друг на друга и происходят последовательно. 
Вероятность наступления одного события зависит от того, что произошло с предыдущим событием.

Примеры зависимых событий:
1. Из колоды карт вытаскивают 2 карты без возвращения. Вероятность вытащить королеву на второй картой зависит от того, 
    была ли вытащена королева на первой карте.
2. Вероятность того, что ведро с шариками содержит 5 красных и 5 зеленых шаров, зависит от того, 
    возьмете ли вы первый шар без возвращения перед выбором второго.

Независимые события - это события, которые не оказывают влияния друг на друга и происходят независимо друг от друга. Вероятность наступления одного события не зависит от того, что произошло с предыдущим событием.

Примеры независимых событий:
1. Бросок монеты. Вероятность выпадения орла или решки не зависит от предыдущих результатов бросков.
2. Бросок кубика. Вероятность выпадения определенной грани не зависит от предыдущих результатов бросков.

Вероятность произведения двух событий отражает вероятность того, что оба эти события произойдут одновременно. 
Формально вероятность произведения двух событий А и В обозначается как P(A и B) или P(A ∩ B).

Если события A и B независимы, то вероятность их произведения равна произведению их индивидуальных вероятностей:
    P(A и B) = P(A) * P(B)

Например, пусть есть две независимые монеты. Вероятность того, что первая монета выпадет орлом (A) равна 0.5,
а вероятность того, что вторая монета выпадет орлом (B), также равна 0.5.
Вероятность того, что обе монеты выпадут орлами, будет:
    P(A и B) = 0.5 * 0.5 = 0.25

То есть вероятность произведения двух независимых событий равна произведению их индивидуальных вероятностей.

Если же события A и B зависимы, то вероятность их произведения вычисляется с использованием условной вероятности:
    P(A и B) = P(A) * P(B|A), где P(B|A) — это условная вероятность события B при условии, что событие A уже произошло.

Например, пусть есть колода карт. Вероятность вытащить червовую карту из колоды (событие A) равна 1/4, 
а вероятность вытащить туз (событие B), если уже вытащена червовая карта, равна 1/13. 
Тогда вероятность того, что первая карта будет червовая и вторая будет тузом, будет:
    P(A и B) = (1/4) * (1/13) = 1/52

Таким образом, вероятность произведения двух зависимых событий вычисляется с учетом условной вероятности.


СОВЕМЕСТНЫЕ И НЕСОВМЕСТНЫЕ СОБЫТИЯ. СУММА СОБЫТИЙ (Условное ИЛИ)

Совместные события - это события, которые могут произойти одновременно или вместе с другими событиями. 
Например, если у вас есть две монеты, то выпадение орла на одной монете и выпадение орла на другой монете является совместным событием.

Несовместные события - это события, которые не могут произойти одновременно или вместе с другими событиями. Например, если у вас есть две монеты, 
то выпадение орла на одной монете и выпадение решки на другой монете является несовместным событием, так как они не могут произойти одновременно.
Или при игре в Дартс можно расположить мишени так, что бы они пресекались (либо одну на другую) - тогда события МОГУТ быть совместимы, так как появилась возможность
попасть одновременно и в первую и во вторую мишень


Сумма вероятностей совместных и несовместных событий обычно означает 
полную вероятность наступления одного из этих событий.

Сумма вероятностей совместных событий - это вероятность того, 
что произойдет хотя бы одно из событий, представленных в совокупности.
P(A + B) = P(A) + P(B) - P(A * B)

Сумма вероятностей несовместных событий - это вероятность того, что произойдет одно из событий, 
представленных в совокупности, 
исключая возможность наступления другого из них.
P(A + B) = P(A) + P(B)

В общем случае, сумма вероятностей совместных и несовместных событий равна 1, 
так как это представляет всевозможные исходы для данного набора событий.


ФОРМУЛА БЕРНУЛЛИ

Формула Бернулли является одной из основных формул в теории вероятностей
и используется для вычисления вероятности успеха или неудачи в серии независимых 
экспериментов с двумя исходами (успехом и неудачей), при условии, что вероятность 
успеха остается постоянной во всех экспериментах.

Формула Бернулли имеет следующий вид:

P(X=k) = C(n, k) * p^k * (1-p)^(n-k),

где P(X=k) - вероятность того, что в серии из n экспериментов произойдет k успехов,
C(n, k) - число сочетаний из n по k (т.е. количество возможных комбинаций, в которых можно выбрать k успехов из n экспериментов),
p - вероятность успеха в одном эксперименте,
(1-p) - вероятность неудачи в одном эксперименте,
k - количество успехов в серии из n экспериментов,
n - общее количество экспериментов.

Формула Бернулли позволяет оценить вероятность получить определенное количество 
успехов в серии независимых экспериментов, где вероятность успеха постоянна. 
Она широко используется в различных областях, таких как статистика, экономика, 
физика, биология и др., где важно знать вероятность наступления определенного события 
при условии проведения серии экспериментов.


ФОРМЛУ ПОЛНОЙ ВЕРОЯТНОСТИ

Формула полной вероятности помогает рассчитать вероятность наступления события, 
основываясь на вероятностях других связанных событий. Это особенно полезно, 
когда необходимо рассмотреть все возможные исходы ситуации.

Формула полной вероятности выглядит следующим образом:

P(A) = P(A1) · P(B1|A) + P(A2) · P(B2|A) + ... + P(An) · P(Bn|A),

где P(A) - вероятность наступления события А,
А1, А2, ..., Аn - различные состояния, при которых может произойти событие А,
P(A1), P(A2), ..., P(An) - вероятности состояний, при которых может произойти событие А,
B1, B2, ..., Bn - связанные события, которые могут произойти при каждом из состояний А,
P(B1|A), P(B2|A), ..., P(Bn|A) - условные вероятности событий B1, B2, ..., Bn при каждом из состояний А.

Чтобы использовать формулу полной вероятности, необходимо знать вероятности 
состояний А и условные вероятности событий B1, B2, ..., Bn при каждом из состояний А. 
Затем мы умножаем каждую вероятность состояния А на условную вероятность соответствующего события 
Bi и суммируем все полученные значения. Результат будет вероятностью наступления события А.

Формула полной вероятности является мощным инструментом в теории вероятностей и позволяет 
учитывать различные варианты развития событий при анализе сложных ситуаций.



ФОРМУЛА БАЙЕСА

Формула Байеса в теории вероятностей используется для вычисления 
условной вероятности одного события при условии, что произошло другое событие. 
Она выглядит следующим образом:

P(A|B) = (P(B|A) * P(A)) / P(B)

Где:
P(A|B) - условная вероятность события A при условии, что произошло событие B
P(B|A) - условная вероятность события B при условии, что произошло событие A
P(A) и P(B) - вероятности событий A и B соответственно

Формула Байеса позволяет пересчитывать вероятности событий на основе полученной информации. 
Она основана на теореме о полной вероятности, которая утверждает, что вероятность произошедшего события 
B можно вычислить как сумму произведений вероятностей события B при условии различных возможных значений события A, 
умноженных на вероятность события A.

Формула Байеса находит широкое применение в различных областях, включая статистику, машинное обучение, 
обработку естественного языка, искусственный интеллект, биоинформатику и др. Она позволяет учитывать 
новую информацию и обновлять исходные вероятности, что делает ее мощным инструментом для принятия решений 
на основе статистических данных.





/////////// ЧАСТЬ 2 ///////////




СЛУЧАЙНАЯ ВЕЛИЧИНА, ПЛОТНОСТЬ И ФУНКЦИЯ РАСПРЕДЕЛЕНИЯ

Случайная величина в теории вероятностей - это функция, которая присваивает 
числовое значение каждому исходу случайного эксперимента. 
В качестве примера, можно рассмотреть случайную величину "результат броска кубика", 
которая может принимать значения от 1 до 6.

Для характеризации случайной величины используются плотность и функция распределения.

Плотность распределения (density function) - это функция, которая 
описывает вероятностную структуру случайной величины. Иными словами, 
плотность распределения показывает, как вероятность распределена по 
различным значениям случайной величины. Обозначается обычно как f(x). 
    f(x) = dF(x) / dx 
    где F(x) - функция распределения, а dx - дифференциал переменной x. Плотность распределения вероятности должна удовлетворять следующим условиям:

1. Неотрицательность: f(x) ≥ 0 для всех значений x.
2. Нормализация: Интеграл плотности вероятности по всем возможным значениям x равен единице:
    ∫f(x)dx = 1.


Функция распределения (cumulative distribution function) - это функция, которая 
показывает вероятность того, что случайная величина будет иметь значение меньше или 
равное определенному числу. Обозначается обычно как F(x). 
Вероятность события P(X <= x) выражается через функцию распределения.

Пример:
    Вероятность что случайна величина X попадет в диапозон 3 < X < 4 при бросании кубика = 
    P(3< X < 4) = 4∫3 f(x)dx = F(4) - F(3) = 1/6

Функция распределения и плотность распределения связаны между собой следующим образом: 
плотность распределения можно получить путем дифференцирования функции распределения. 
И наоборот, функция распределения можно получить путем интегрирования плотности распределения.

Знание плотности и функции распределения позволяет решать различные задачи теории вероятностей, 
такие как вычисление вероятностей, математического ожидания, дисперсии и других характеристик 
случайной величины.


Случайная величина может быть дискретной(игральный кубик) и непрерывной(стрельба по мешени)

Ряд распределения представляет собой обычную таблицу:
    X | 1 | 2 | 3 | 4 | 5 | 6 - случайная величина
    P | 1/6 | 1/6 | 1/6 | 1/6 | 1/6 | 1/6 - вероятность события

Евклидово расстояние для случайной величины (при стрельбе по мишени) X = L = √(x1 - x0)² + (y1 - y0)²


ВИДЫ ПРВ, ФОРМУЛА ГАУССА, РЭЛЕЯ, 

Формула Гауссова (нормального) распределения, 
также известная как фишеровская или Гаусса-Лапласа формула, 
определяет вероятность попадания случайной величины в заданный интервал. 
Формула выглядит следующим образом:
    P(x) = (1 / σ√(2π)) * exp(-((x - μ)^2 / (2σ^2)))
    где:
        P(x) - вероятность попадания случайной величины x в интервал,
        σ - стандартное отклонение или среднеквадратическое отклонение,
        μ - математическое ожидание или среднее значение.

Формула Гауссова распределения широко применяется в статистике, 
экономике, естественных науках и других областях, где требуется 
моделирование случайных величин.


Формула Рэлея для функции плотности вероятности выглядит следующим образом:
    f(x) = (x/σ^2) * exp(-(x^2/2σ^2))
    где x - случайная величина, σ - параметр масштаба.
Часто используется в связке с формулой вычисления случайно велични через Евклидово расстояние


Формула экспоненциального распределения выглядит следующим образом:
    f(x) = λ * e^(-λx)
        где:
        - f(x) - плотность вероятности случайной величины x,
        - λ - параметр интенсивности (частоты событий),
        - e - основание натурального логарифма.
Эта формула описывает вероятность того, что случайная величина x примет определенное значение в данном интервале.


ХАРАКТЕРИСТИКИ СЛУЧАЙНОЙ ВЕЛИЧИНЫ

////////// МАТ.ОЖИДАНИЕ //////////
Математическое ожидание — это понятие в теории вероятностей, 
которое представляет собой среднее значение случайной величины. 
Формула для вычисления математического ожидания может зависеть от конкретной случайной величины.

Для дискретной случайной величины X формула выглядит следующим образом:
E[X] = ∑(x * P(X = x)), где x принимает все возможные значения случайной величины, 
а P(X = x) представляет собой вероятность, что случайная величина X равна x.

Для непрерывной случайной величины X формула выглядит следующим образом:
E[X] = ∫(x * f(x) dx), где f(x) представляет собой функцию плотности вероятности случайной величины X.

Математическое ожидание используется для описания среднего значения 
случайной величины и позволяет предсказывать, какие значений можно 
ожидать в долгосрочной перспективе. Оно является важным показателем в 
различных областях, например, в финансах, статистике, экономике, 
инженерии и других.

Вычисление математического ожидания позволяет определить, 
сколько в среднем можно ожидать получить или потерять на 
основе вероятностей различных значений случайной величины. 
Также математическое ожидание может использоваться для 
сравнения и анализа различных случайных процессов или моделей.

Формлуа мат.ожидания m(приблезительное)(x) = 1 / N  ∑a>i


////////// МЕДИАНА //////////
Медиана случайной величины – это значение, которое располагает половину наблюдений в выборке выше себя и половину ниже.
Формула для расчета медианы зависит от типа данных. Для дискретных случайных величин медиану можно найти следующим образом:
    1. Упорядочить выборку в порядке возрастания или убывания.
    2. Если выборка состоит из нечетного числа элементов, то медиана будет равна среднему значению среднего элемента выборки.
    3. Если выборка состоит из четного числа элементов, то медиана будет равна среднему значению двух средних элементов.

Для непрерывных случайных величин медиана может быть найдена следующим образом:
    1. Найти функцию распределения случайной величины.
    2. Решить уравнение F(x) = 0,5, где F(x) – функция распределения, а 0,5 – вероятность.

Медиана является одной из основных мер центральной тенденции. 
Она позволяет оценить типичное значение выборки, не зависящее от 
выбросов или экстремальных значений. Медиана также устойчива к асимметрии и выбросам в данных.

Медиана находит широкое применение во многих областях, таких как статистика, 
экономика, медицина и социальные науки. Она может использоваться для описания 
среднего значения доходов, расходов, оценки среднего значения времени или возраста и т.д.

////////// МОДА //////////
Мода случайной величины - это значение, которое встречается наиболее часто в наборе данных.
Формула для расчета моды зависит от типа случайной величины. Для дискретной случайной величины, 
мода может быть определена как значение с наибольшей частотой. 
Для непрерывной случайной величины, мода может быть определена как значение, 
при котором функция плотности вероятности достигает максимума.

Мода является одним из показателей центральной тенденции и используется для 
описания основного значения набора данных. Она помогает выявить наиболее 
типичные значения в распределении и может использоваться для выявления особенностей
или аномалий в данных.

Мода применяется в различных областях, включая статистику, экономику, социологию и маркетинг, 
чтобы анализировать и интерпретировать данные. Например, в маркетинге мода может использоваться 
для определения наиболее популярного продукта среди потребителей. В медицине мода может использоваться 
для определения наиболее распространенного симптома у больных.


////////// 2-Й ЦЕНТРАЛЬНЫЙ МОМЕНТ ИЛИ ДИСПЕРСИЯ СЛУЧАЙНОЙ ВЕЛИЧИНЫ //////////

- Мера разброса случайной величины

Дисперсия случайной величины является мерой разброса значений случайной величины относительно её математического ожидания. 

Формула для вычисления дисперсии случайной величины X:
    Var(X) = E[(X - E(X))^2]
    где Var(X) - дисперсия X,
    E[X] - математическое ожидание X.

Обычно вычисление дисперсии включает следующие шаги:
    1. Вычисление математического ожидания X (E[X]).
    2. Вычисление разности между каждым значением X и E[X] (X - E(X)).
    3. Возвести каждую разность в квадрат [(X - E(X))^2].
    4. Вычислить среднее значение квадратов [(X - E(X))^2] - это и будет дисперсия Var(X).

Интерпретация дисперсии заключается в том, что она позволяет оценить, 
насколько значения случайной величины отклоняются от её математического ожидания. 
Чем больше дисперсия, тем больше разброс значений случайной величины относительно её среднего значения. 
И наоборот, чем меньше дисперсия, тем меньше разброс значений.

Среднее квадратное отклонение (standard deviation)
действительно является корнем из дисперсии (variance).
Дисперсия - это среднее значение квадратов отклонений
каждого значения от среднего значения выборки.
Измеряется в квадратных единицах измерения и показывает разброс значений относительно среднего значения выборки.
Среднее квадратное отклонение получается извлечением корня из дисперсии и измеряется в тех же единицах, что и исходные данные.
Оно показывает стандартное отклонение значений относительно среднего значения выборки и служит для измерения разброса данных

////////// МОДЕЛИРОВАНИЕ СЛУЧАЙНЫХ ВЕЛИЧИН //////////




////////// СИСТЕМА СЛУЧАЙНЫХ ВЕЛИЧИН //////////
Например:
    При стрельбе по мишени, точку попадания можно представить двумя случайными величинами X(координата абцисс), Y(координата ординат)
    Для описания положения самолета в пространстве X, Y, Z


Часто записываются в виде Матрицы [X, Y]^T или просто | X |
                                                      | Y |      
Система случайных величин - это набор случайных величин, которые могут быть связаны друг с другом или зависеть от общих факторов.

Такая система может использоваться для моделирования и анализа различных случайных процессов, 
например, в финансовой математике, теории вероятностей, статистике и других областях.

Зачем использовать систему случайных величин:
1. Моделирование стохастических процессов: система случайных величин позволяет описать эволюцию 
случайной величины или набора случайных величин во времени или пространстве.
2. Анализ вероятностей и статистика: система случайных величин позволяет рассчитывать вероятности 
событий и доверительные интервалы, а также проводить статистический анализ данных.
3. Решение оптимизационных задач: система случайных величин может использоваться для поиска 
оптимальных решений при наличии случайных факторов.

Формула для системы случайных величин зависит от конкретной задачи и модели. Например, для случайных величин X1, X2, ..., Xn, 
которые являются независимыми и одинаково распределенными, можно использовать следующую формулу для расчета их суммы:
    S = X1 + X2 + ... + Xn
    где S - сумма случайных величин.

Двумерная плотность распределения вероятности:
    Формула двумерной плотности вероятности, также известная как функция плотности вероятности, 
    используется для описания вероятностей случайных переменных в двумерном пространстве.
    Общая формула плотности вероятности для двумерной случайной величины (X, Y) выглядит следующим образом:
        f(x, y) = P((X, Y) принимает значение (x, y))
    Также можно записать в виде:
        f(x, y) = dF(x, y) /dxdy,
        где F(x, y) - функция распределения двумерной случайной величины (X, Y), а dxdy - дифференциал площади.

    Двумерная плотность вероятности позволяет определить вероятность попадания случайной величины в определенную 
    область двумерного пространства. Она часто используется в статистике, экономике, физике и других науках для анализа и моделирования различных явлений. 

    Например, можно использовать двумерную плотность вероятности для анализа зависимости двух случайных величин 
    друг от друга или для определения вероятности совместного появления двух событий.

    Оценка двумерной плотности вероятности позволяет проводить дальнейший анализ, такой как нахождение условных 
    вероятностей, математических ожиданий и других характеристик двумерного распределения.


Двумерная функция распределения случайной величины (joint distribution function) 
описывает вероятность того, что две случайные величины примут значения, не превышающие заданных значений.
Обозначается как F(x, y), где x и y - значения двух случайных величин.

Функция распределения задается следующим образом:
    F(x, y) = P(X ≤ x, Y ≤ y),
    где X и Y - случайные величины, а P(X ≤ x, Y ≤ y) - вероятность события, когда X ≤ x и Y ≤ y.

Двумерная функция распределения должна удовлетворять следующим свойствам:
    1) Неотрицательность: F(x, y) ≥ 0 для всех x и y.
    2) Монотонность: Если x1 < x2 и y1 < y2, то F(x1, y1) ≤ F(x2, y2).
    3) Ограниченность: 0 ≤ F(x, y) ≤ 1 для всех x и y.
    4) Неубывающая функция: Если x1 ≤ x2, то F(x1, y) ≤ F(x2, y) и F(x, y1) ≤ F(x, y2) для любых y1 и y2.
    5) Пределы вероятности: При x → -∞ или y → -∞, F(x, y) → 0, а при x → +∞ или y → +∞, F(x, y) → 1.

Двумерная функция распределения позволяет оценить совместное распределение двух случайных 
величин и рассчитать различные характеристики, такие как среднее значение, ковариация, корреляция и другие.

Если необходимо расчитать вероятность попадания двумерной случайной величины в какую-то определенную область(любой формы) можно использовать формулу:
    P((X, Y) ∈ D ) = ∫∫w(x,y)dxdy - Данная формула представляет собой формулу для вычисления вероятности того, 
                                    что случайная величина (X, Y) попадет в некоторое множество D. В этой формуле ∫∫ обозначает двойной интеграл, 
                                    а w(x, y) – плотность вероятности двумерной случайной величины (X, Y). Подставляя вместо w(x, y) плотность 
                                    вероятности конкретного распределения, можно вычислить вероятность для конкретной двумерной случайной величины.


Напомним: Плотность распределения случайной величины - это функция, которая описывает вероятность того, 
          что случайная величина примет определенное значение или попадёт в определенный диапазон значений. 
          Плотность распределения может быть использована для вычисления вероятности различных событий или 
          для анализа вероятностных свойств случайной величины. Она обычно представлена графически в виде графика.


////////// ЗАВИСИМОСТЬ СЛУЧАЙНЫХ ВЕЛИЧИН, КОВАРАЦИЯ, КОРРЕЛЯЦИЯ //////////

Зависимость случайных величин:
    Зависимость случайных величин означает, что значения одной случайной величины зависят от значений другой случайной величины. 
    Зависимость может быть причинно-следственной, статистической или корреляционной.

Ковариация:
    Ковариация - это мера силы и направления линейной зависимости между двумя случайными величинами. 
    Она измеряет, насколько значения одной случайной величины меняются вместе с изменением значений другой случайной величины. 
    Ковариация может быть положительной, отрицательной или нулевой. Положительная ковариация указывает на прямую зависимость, отрицательная - на обратную зависимость, 
    а нулевая - на отсутствие зависимости.

Корреляция:
    Корреляция - это стандартизированная мера статистической зависимости между двумя случайными величинами. В отличие от ковариации,
    корреляция измеряется от -1 до 1, что позволяет сравнивать зависимости разных масштабов. 
    Корреляция близкая к 1 указывает на сильную положительную зависимость, к -1 - на сильную отрицательную зависимость, а к 0 - на отсутствие зависимости.

Корреляция и ковариация оба показывают наличие или отсутствие взаимосвязи между случайными величинами, но корреляция является более объективной мерой, 
так как она стандартизована и не зависит от масштаба измерения


формула двумерной плотности распределения для независимых X, Y : w(x, y) = w1(x) * w2(y) =>
    то есть плотность распределения двух сл.чисел = произведению каждой отдельной плотности для каждой отдельной сл.величины
А если зависимы то: w(x, y) = w1(x) * w(x|y) = w2(y) * w(x|y)



////////// ТЕОРЕМА ЧЕБЫШЕВА ////////// 

Теорема Чебышева (или неравенство Чебышева) является одним из основных результатов теории вероятностей и статистики. 
Её формулировка устанавливает ограничение на вероятность отклонения случайной величины от её математического ожидания.

Для независимых случайных величин:
    Пусть X - случайная величина с конечным математическим ожиданием µ и дисперсией σ^2. Тогда для любого положительного числа k выполняется неравенство Чебышева:
    P(|X - µ| ≥ kσ) ≤ 1 / k^2.

Для зависимых случайных величин:
    Пусть X1, X2, ..., Xn - набор зависимых случайных величин с конечными математическими ожиданиями и дисперсиями. 
    Тогда для любого положительного числа k выполняется неравенство Чебышева:
        P(|X1 - µ1| ≥ kσ1, |X2 - µ2| ≥ kσ2, ..., |Xn - µn| ≥ kσn) ≤ 1 / k^2,
        где µi - математическое ожидание случайной величины Xi, σi - стандартное отклонение случайной величины Xi.

Неравенство Чебышева позволяет оценить вероятность отклонения случайной величины от её математического ожидания, не требуя знания о её распределении. 
Оно указывает на то, что чем больше значение k, тем меньше вероятность отклонения случайной величины X от её математического ожидания µ.